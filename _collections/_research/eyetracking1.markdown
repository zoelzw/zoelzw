---
layout: idea
title:  "Gaze Fixation Comparisons Between Amputees and Able-bodied Individuals in Approaching Stairs and Level-ground Transitions: A Pilot Study"
date:   2019-06-23 
description: Where do amputees look at when they approach to stairs? How can we use this information to prepare robotic prothesis for stairs?
image: https://github.com/zoelzw/zoelzw/blob/master/assets/Eyetracking1.png?raw=true
---
<div class="row">
  <div class="col-md-4">
  <p class = "lead">
    <b>Skills:</b> <br>
    programming (MATLAB, Tobii Pro SDK);<br>
    self-learning;<br>
    experimental design;<br>
    data collection and analysis;<br>
    research paper writing;<br>
    problem solving
  </p>
  </div>
  <div class="col-md-8">
  <!-- <h1>{{ page.title }}</h1> -->
    <p class="lead">Gaze Fixation Comparisons Between Amputees and Able-bodied Individuals in Approaching Stairs and Level-ground Transitions: A Pilot Study <br>
    <br>Minhan Li, Boxuan Zhong, <strong>Ziwei Liu</strong>, I-Chieh Lee, Bretta L. Fylstra, Edgar Lobaton and He Helen Huang. 
    <br><i>IEEE EMBC 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society</i>, 2019
    </p>
  </div>
</div>
<hr bordercolor = "lightgrey">

<div class="row">
  <div class="col-md-6">
    <img src="https://github.com/zoelzw/zoelzw.github.io/blob/master/assets/eye0.png?raw=true" style='height: 100%; width: 100%; object-fit: contain'/>
  </div>
  
  <div class="col-md-6">
    <br>
    <h2>Motivation</h2>
    <p> 
      Previous studies have demonstrated the fundamental significance of the visual system in navigating in complex terrains. It provides environmental feature extraction to guide immediate foot placement and builds a spatial map of the surroundings to plan the route for succeeding steps and/or rapid reactions to unexpected perturbations. 
    </p>
    <p>
      Where do amputees look when they approach stairs? What can we do with this information to design a co-adaptation system for amputees and robotic prothesis? 
    </p>
     <p> 
      <i class="fa fa-chevron-right"></i> This paper aims to investigate the visual strategy of transtibial amputees while they are approaching the transition between level-ground and stairs and compare it with that of able-bodied individuals. To this end, we conducted a pilot study where two transtibial amputee subjects and two able-bodied subjects transitioned from level-ground to stairs and vice versa while wearing eye tracking glasses to record gaze fixations.
    </p>
  </div>
</div>
<hr bordercolor = "lightgrey">

<div class="row">
  <div class="col-md-6">
    <br>
    <img src="https://github.com/zoelzw/zoelzw.github.io/blob/master/assets/Eyetracking1.png?raw=true" style='height: 100%; width: 100%; object-fit: contain'/>
  </div>
  
  <div class="col-md-6">
    <br>
    <h2>Contribution</h2>
    <p> 
      I worked as a Research Assistant throughout this project, including experimental design, data collection and analysis, and paper writing. I particularly enjoyed working with amputee participants and learning their feedbacks on Assistive Technology and emerging technologies such as eye tracking. 
    </p>
    <p>
      I learned about Tobii Pro Glasses 2 and Tobii Eye Tracking SDK and led data processing using Tobii Pro Lab software. I also learned how to illustrate key concepts and results in this study using Adobe Illustrator and MATLAB. 
    </p>
    <p> 
      This study has shown different visual strategies are used between transtibial amputees and able-bodied popula- tions when they were approaching stairs and level-ground transitions. Transtibial amputees show more dependence on their vision to perform challenging locomotor tasks.
    </p>
  </div>
</div>
<hr bordercolor = "lightgrey">

<div class="row">
  <div class="col-md-6">
  <br>
    <h2>And beyond...</h2>
    <br>
     <p> 
      Importantly, these findings can potentially lead us to develop innovative technologies to assist amputees during navigation of these locomotor tasks. For example, by identifying the relationship between gaze behavior patterns and upcoming terrains, a real-time algorithm could be devised for predicting locomotion modes, thereby enhancing the control of robotic prostheses.
    </p>
    <p> 
      I particularly enjoyed working with amputee participants and learning their feedbacks on Assistive Technology and emerging technologies such as eye-tracking. 
    </p>
    <p> 
       I was also fascinated by how much information can be conveyed by gaze and fixation patterns. I conducted another pilot study using eye-tracking technology. <a href="https://zoelzw.github.io/research/Eyetracking2.html" style="text-decoration: none; border-bottom: 1px solid #ff0000; color: #000000;">More details</a> 
    </p>
  </div>

  <div class="col-md-6">
    <br>
    <!-- <div class="img-fluid rounded mt-2 mb-2 mb-md-0" style="background-image: url(https://github.com/zoelzw/zoelzw.github.io/blob/master/assets/Embodiment.png?raw=true);  height: 50vh; background-position:center;"> -->
    <img src="https://github.com/zoelzw/zoelzw.github.io/blob/master/assets/Tobii1.png?raw=true" style='height: 100%; width: 100%; object-fit: contain'/>
  </div>
</div>
